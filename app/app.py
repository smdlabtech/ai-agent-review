# --- Supprime les warnings gRPC/ALTS *avant* tout import Google/gRPC ---
import os
os.environ.setdefault("GRPC_VERBOSITY", "ERROR")   # gRPC: afficher seulement les erreurs
os.environ.setdefault("GLOG_minloglevel", "2")     # Abseil/GLOG: ERROR et plus

import json
import streamlit as st
from dotenv import load_dotenv

from src.agent_builder import SmartAgent

# Charge les variables d'environnement (.env)
load_dotenv()

# ---------------- UI & Config ----------------
st.set_page_config(page_title="AI Agent Review", page_icon="üß†", layout="wide")

st.title("üß† AI Agent Review - Chatbot")
st.caption("Streamlit ¬∑ OpenAI / Gemini ¬∑ Memory (buffer) ¬∑ Cloud Run-ready")

with st.sidebar:
    st.header("‚öôÔ∏è Configuration")

    provider = st.selectbox("Provider", ["gemini", "openai"], index=0)

    # Valeur par d√©faut du mod√®le selon le provider + .env
    default_model = (
        os.getenv("GEMINI_MODEL", "gemini-1.5-flash")
        if provider == "gemini"
        else os.getenv("OPENAI_MODEL", "gpt-4o-mini")
    )
    model = st.text_input("Model", value=default_model)

    # Contr√¥les optionnels (appliqu√©s apr√®s instanciation si support√©s)
    temperature = st.slider("temperature", 0.0, 1.5, 0.2, 0.1)
    max_tokens = st.number_input(
        "max_tokens (r√©ponse)", min_value=128, max_value=8192, value=1024, step=64
    )
    memory_mode = st.selectbox("M√©moire", ["short_term", "none"], index=0)

    st.markdown("---")
    st.write("üîê Assurez-vous d'avoir configur√© votre `.env`.")
    st.code("cp .env.example .env", language="bash")
    st.markdown("---")
    st.write("üí° Astuce: gardez `temperature` faible pour des r√©ponses stables.")

    col_a, col_b = st.columns(2)
    with col_a:
        reset_chat = st.button("‚ôªÔ∏è R√©initialiser la conversation", use_container_width=True)
    with col_b:
        reset_agent = st.button("üîÑ R√©initialiser l‚Äôagent", use_container_width=True)

# ---------------- Session State & Reset ----------------
if "messages" not in st.session_state:
    st.session_state.messages = []

if reset_chat:
    st.session_state.messages = []
    st.rerun()

# ---------------- Cr√©ation / Recr√©ation de l'agent ----------------
need_new_agent = (
    "agent" not in st.session_state
    or st.session_state.get("provider") != provider
    or st.session_state.get("model") != model
    or reset_agent
)

if need_new_agent:
    # Si tu utilises google.generativeai (Gemini), forcer REST √©vite gRPC et ALTS.
    if provider == "gemini":
        os.environ.setdefault("GENAI_TRANSPORT", "rest")  # √† lire dans SmartAgent si applicable

    # IMPORTANT: ne pas passer temperature/max_tokens ici (rupture de signature)
    agent = SmartAgent(
        tools=[],                   # branche tes tools ici si besoin
        memory=memory_mode,         # "short_term" / "none"
        planner="reactive",         # ex: "plan_act_reflect" si dispo
        provider_name=provider,
        model=model,
    )

    # Couche de compatibilit√© : appliquer temperature/max_tokens si support√©s
    applied = False
    try:
        if hasattr(agent, "set_generation_params") and callable(agent.set_generation_params):
            agent.set_generation_params(temperature=temperature, max_tokens=max_tokens)
            applied = True
        elif hasattr(agent, "configure") and callable(agent.configure):
            # Beaucoup de classes exposent une m√©thode configure(**kwargs)
            agent.configure(temperature=temperature, max_tokens=max_tokens)
            applied = True
        else:
            # Dernier recours : set d‚Äôattributs s‚Äôils existent / sont accept√©s
            setattr(agent, "temperature", temperature)
            setattr(agent, "max_tokens", max_tokens)
            applied = True
    except Exception:
        # On ignore proprement si l‚Äôagent ne supporte pas ces options
        applied = False

    st.session_state["agent"] = agent
    st.session_state["provider"] = provider
    st.session_state["model"] = model

    # Info discr√®te c√¥t√© UI si l‚Äôapplication des param√®tres a r√©ussi/√©chou√©
    with st.sidebar:
        if applied:
            st.caption("‚úÖ Param√®tres de g√©n√©ration appliqu√©s √† l‚Äôagent.")
        else:
            st.caption("‚ÑπÔ∏è Param√®tres non pris en charge par SmartAgent (ignor√©s).")

# ---------------- Chat UI ----------------
# Historique
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# Entr√©e utilisateur
user_input = st.chat_input("Posez votre question √† l'agent‚Ä¶")

if user_input:
    # Affiche + stocke le message utilisateur
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # R√©ponse de l'agent
    with st.chat_message("assistant"):
        with st.spinner("R√©flexion de l'agent‚Ä¶"):
            try:
                reply = st.session_state.agent.run(user_input)

                # Si l'agent retourne un dict (citations, sources...), rendre proprement
                if not isinstance(reply, str):
                    reply = "```json\n" + json.dumps(reply, ensure_ascii=False, indent=2) + "\n```"
            except Exception as e:
                reply = f"‚ùå Erreur: {e}"

        st.markdown(reply)

    # Stocke la r√©ponse
    st.session_state.messages.append({"role": "assistant", "content": reply})
